[tool: LRC Maker https://lrc-maker.github.io]
[length: 12:02.99]
[00:09.73] Coming up on today's show, Bitcoin's price is up over 20% this year.
[00:14.61] Many investors believe its value will continue to rise,
[00:17.69] but what does the history of technology say about Bitcoin's future?
[00:21.57] WSJ columnist, Jason Zweig, joins us.
[00:24.25] And then, internal reports at Meta found that new paid subscription tools on Facebook and Instagram were being used to exploit children.
[00:31.90] WSJ reporter, Katherine Blunt, joins us to talk about the investigations and how the company chose to address the problems.
[00:40.11] But first, only 21 million Bitcoin will probably ever exist.
[00:45.74] That sounds like a lot, but that limited quantity means that right now everyone wants a piece of it.
[00:51.16] Bitcoin's price is up 22% so far this year,
[00:54.38] but just because something is scarce doesn't mean it'll always be valuable.
[00:58.36] Jason Zweig writes WSJ's Intelligent Investor column, and he joins us now with more on what that could mean for Bitcoin's future.
[01:05.67] Jason, you make a comparison between gold and pearls and link that to Bitcoin.
[01:10.26] Break this down for us.
[01:11.31] Jason Zweig: Gold is, of course, scarce, and it's been a rare and desirable commodity for thousands of years all around the world, but so have pearls.
[01:24.06] Pearls have a very long multi-thousand year history of being very desirable and valuable.
[01:30.42] But starting in the 1920s, artificial pearls came along
[01:35.06] and they pretty much ruined the market for natural pearls for decades.
[01:40.49] And it's only recently started to recover,
[01:43.55] although it still isn't back to where it was a century ago.
[01:46.79] So scarcity and desirability are not actually a guarantee that any asset will retain its value over the long run.
[01:58.80] Alex Ossola: And Bitcoin is scarce, its supply is finite.
[02:01.70] So is Bitcoin more like gold or pearls?
[02:04.88] Jason Zweig: The best way to think about it is Bitcoin is a disruptive technology.
[02:10.49] It has the potential to shove traditional forms of money aside and replace them with digital currencies and digital transaction platforms
[02:22.59] that don't involve cash or traditional forms of credit or other financial exchange.
[02:29.82] But disruptive technologies can themselves be disrupted.
[02:35.74] And a pearl is this incredibly rare and beautiful thing.
[02:40.63] But Mikimoto, the Japanese firm, came along late in the 19th and early in the 20th century and perfected the art of creating cultured pearls.
[02:52.37] And in the column I tell the story of a pearl necklace that was worth a million dollars in 1917,
[03:00.55] that 40 years later had lost 85% of its value without even adjusting for inflation.
[03:08.01] And if it were to sell today, it still would be worth far less than it was over a century ago,
[03:16.88] and that's the power of disruption.
[03:20.00] Alex Ossola: Last month, the SEC approved Bitcoin ETFs.
[03:23.14] So how does that change the way Bitcoin is valued?
[03:26.13] Jason Zweig: Bitcoin is up roughly 20% so far this year,
[03:30.19] largely on the belief that the demand from individual investors, partly through these new Bitcoin ETFs,
[03:41.49] will continue to drive up the price.
[03:44.79] And so far it certainly has.
[03:47.37] The history of mass entry into a market by individual investors isn't always a positive thing in the long run.
[03:58.33] When gold ETFs were introduced decades ago, they led to a short-term surge in the price of gold, but not a particularly durable one.
[04:11.92] Individual investors buying Bitcoin ETFs is certainly no guarantee that Bitcoin will continue to go up in price,
[04:19.71] but it is certainly a positive sign in the short run.
[04:24.53] And if Bitcoin becomes part of the asset allocation plans of big firms, like BlackRock or Fidelity,
[04:35.71] then that could definitely lead to sustained demand in the long run.
[04:41.58] Alex Ossola: That was Jason Zweig, who writes The Intelligent Investor column every week for the Wall Street Journal.
[04:46.48] Coming up, Meta staff found that new paid subscription tools on Facebook and Instagram were being used to exploit children.
[04:53.26] We'll find out how Meta chose to address it after the break.
[05:10.48] Last year, Meta began a broad rollout of tipping and paid subscription services on Facebook and Instagram.
[05:17.02] The services were meant to help influencers earn more money by selling exclusive content to subscribers.
[05:22.57] Those influencers included parents running accounts for their children to become models,
[05:27.25] but an internal report from Meta found that
[05:29.96] some parent-run minor accounts were catering to users who had demonstrated pedophilic interests elsewhere on the platform.
[05:35.97] Meta says its programs are well monitored.
[05:38.31] WSJ reporter, Katherine Blunt, joins me now with more on the investigation and how Meta addressed the problems.
[05:44.66] Katherine, tell me about these new paid subscription tools on Facebook and Instagram.
[05:48.57] Katherine Blunt: So Meta, within the last year or so, began rolling out these tools
[05:53.06] to help content creators monetize the posts and the reels that they were putting out on Instagram, in particular.
[05:59.20] It's a very popular platform for influencers, and it's available to all kinds of different accounts.
[06:05.52] But in particular, Meta began looking into how these tools are being used on
[06:09.95] what are known as parent-run minor accounts or children's accounts that are managed by their parents.
[06:15.94] Alex Ossola: Yeah. How have those been used to exploit children?
[06:19.19] Katherine Blunt: Right. So an internal investigation found that there were some parents who were really misusing these tools.
[06:27.36] So the way it works in this ecosystem is that there are a lot of accounts, children's accounts,
[06:33.54] that maybe they are showing off their dance prowess, maybe they are modeling dance wear or athletic wear.
[06:39.87] And with that, some of them sell subscriptions and it offers the opportunity for followers to pay for additional exclusive content.
[06:47.72] In many cases, that's simply more of what they post on their regular free page,
[06:54.23] maybe outtakes from the photo shoot, or here's another few outfits.
[06:58.46] The other thing that I should say is that it's been determined that a lot of men, possibly with untoward interest in children, follow these accounts.
[07:08.16] And the misuse came from when some parents were interacting with these subscribers,
[07:14.03] understanding that they were consuming the content for their own sexual gratification,
[07:17.67] talking with subscribers in a way that was inappropriate as it related to their child.
[07:22.50] In some cases, seeming to sell photos off-platform.
[07:25.93] I mean, just things that really started to get into the territory of being borderline or really crossing a line for Meta.
[07:33.00] Alex Ossola: So Meta did an internal investigation into these tools.
[07:37.02] What did safety staffers recommend the company do about it?
[07:40.23] Katherine Blunt: So there were a few recommendations.
[07:42.24] One, could have been that the company not allow for child modeling accounts like a couple of rival platforms.
[07:47.89] I believe TikTok has significantly restricted that.
[07:51.42] Or another suggestion would be that the parent-run minor accounts, as they're called, register themselves so that Meta
[07:57.65] could try to keep tabs on their activity in the interest of child safety.
[08:01.46] And ultimately, the company did not move forward with these recommendations
[08:05.39] and instead continued to roll out these subscription tools more broadly
[08:08.89] without having what the safety staff considered to be appropriate guardrails in place.
[08:13.45] Alex Ossola: Meta, as you said, didn't pursue those recommendations.
[08:16.50] Instead, they chose to build an automated system.
[08:18.94] What is the system and what are some of the issues with it?
[08:21.94] Katherine Blunt: With this system, the company is essentially trying to determine which users exhibit potentially predatory behavior.
[08:30.59] Maybe the potentially predatory account was blocked by a large number of adult-run minor accounts,
[08:36.78] or maybe it was found to have been searching for truly illicit content as it relates to children or leaving creepy comments.
[08:47.95] And that would essentially result in some penalties or create a score, so to speak,
[08:53.75] that could potentially get you booted off the platform for one.
[08:57.18] But also they were looking at trying to, if an account exhibited this behavior, not allow them to subscribe to children.
[09:03.74] Relatively easily evaded if a user were to set up another account.
[09:07.44] And a lot of these accounts that we're talking about are burners.
[09:10.32] They're just there to consume content and easily deleted and created on a different device or what have you.
[09:16.40] So there's ways around it.
[09:17.78] Alex Ossola: What did Meta say about this?
[09:19.39] Katherine Blunt: Meta says its efforts to address this problem is part of its ongoing safety work,
[09:23.22] that the tools that they have in place are becoming more effective,
[09:26.25] and that it's going to continue to look at this problem and determine what can be done to really make sure that accounts featuring children are appropriately protected.
[09:35.02] Alex Ossola: Catherine, you and our colleague, Jeff Horwitz, have been reporting on child safety issues at Meta for months.
[09:40.14] How has Meta dealt with child safety issues in the past?
[09:43.08] Katherine Blunt: Meta has had a pretty checkered record on this front.
[09:46.62] So last year in June, the Journal published a story demonstrating that the company's algorithms were actively facilitating connections between users with pedophilic interests
[09:57.01] and those that were seeking to purchase illegal child sexual abuse material.
[10:01.51] And that story resulted in the company launching a task force to try to address not only that problem, but some others that had come up in the course of looking into this.
[10:11.71] There's many facets of child safety on Meta platforms.
[10:14.09] It's been really challenging for a number of reasons,
[10:16.39] and they've lost a significant percentage of safety staff over the years as a result of layoffs, but also attrition.
[10:23.06] And building that back up, in a way that's robust enough to address some very complex issues, has been a challenge.
[10:30.64] So this is work that's ongoing, and it's certainly, by the company's own admission, been slower than it would like.
[10:36.60] Alex Ossola: What does all this mean for Meta and its business?
[10:39.05] Katherine Blunt: The company has come under increasing scrutiny.
[10:41.60] There was a significant congressional hearing last month in which CEO Mark Zuckerberg, as well as some other tech CEOs, were questioned by members of Congress about different approaches to child safety.
[10:52.27] It remains to be seen exactly what effect this will have on the business,
[10:57.31] but certainly the company is in the spotlight
[10:59.51] and there's an expectation that they make meaningful progress on some of these very serious issues.
[11:04.78] And all this safety work is coming at a time when the company is working to encrypt messaging,
[11:12.13] and it's already started that process on Facebook, and Instagram will be next.
[11:15.73] And there are real child safety concerns with that
[11:19.56] because messages between minors and adults have often been some of the most effective tools in prosecuting sexual crimes against children.
[11:27.68] As it relates to encryption, Meta has said that it is working to address any safety issues that this shift might present
[11:34.25] and that it has spent years working to try to put in safeguards to prevent unlawful activity on its platforms.
[11:40.45] Alex Ossola: That was our reporter, Katherine Blunt, and that's it for Tech News Briefing. Today's show was produced by Julie Chang, with production help from Cordilia James. Our supervising producer is Katherine Milsop. I'm Alex Ossola for the Wall Street Journal. We'll be back this afternoon with TNB Tech Minute. Thanks for listening.


